input {
  pipeline {
    address => <%= @address %>
  }
}

filter {

  grok {
    pattern_definitions => {"SERVICE_NAME" => "(namenode|resourcemanager|nodemanager|datanode|hive|domain1|mysql|onlinefs|kafka)"}
    match => {"[log][file][path]" => "%{NOTSPACE}%{SERVICE_NAME:service}%{NOTSPACE}.log"}
  }


  if [service] == "domain1" {
    grok {
      # [#|DATETIME|LOG_LEVEL|PRODUCT_ID|LOGGER NAME|OPTIONAL KEY VALUE PAIRS| MESSAGE|#]
      # Date format: 2021-08-09T15:56:26.257+0000
      match => {"message" => "\[#\|%{NOTSPACE:templogdate}\|%{LOGLEVEL:priority}\|%{DATA:product_id}\|%{DATA:logger_name}\|%{GREEDYDATA:key_value_pairs}\|%{GREEDYDATA:log_message}\|#\]"}
    }
  } else if [service] == "mysql" {
    dissect {
      # datetime [string] severity -- message
      # 2021-08-12 09:16:52
      mapping => {"message" => "%{templogdate} [%{logger_name}] %{priority}     -- %{log_message}"}
    }
  } else if [service] == "hive" {
     dissect {
      mapping => {"message" => "%{templogdate} %{priority} %{logger_name}: %{log_message}"}
    }
  } else if [service] == "kafka" {
    dissect {
      mapping => {"[log][file][path]" => "%{}/logs/kafka%{kafka_mod}.log"}
    }
    if [kafka_mod] == "-gc" {
       dissect {
         mapping => {"message" => "%{templogdate}:%{+templogdate}: %{gc_time}: %{log_message}"}
       }
      mutate {
        add_field => {
          "logger_name" => "GC"
        }
      }
    } else {
      dissect {
        mapping => {"message" => "%{templogdate} %{+templogdate} %{priority} %{logger_name}: %{log_message}"}
      }
    }
  } else {
    # Rest of the log4j services
    dissect {
      mapping => {"message" => "%{templogdate} %{+templogdate} %{priority} %{logger_name}: %{log_message}"}
    }
  }

  #Ignore failed parse enties. Grok filter has been tested with http://grokconstructor.appspot.com
  if "_grokparsefailure" in [tags] {
    drop { }
  }

  #Ignore failed parse entries. Dissect filter patterns can be tested with https://dissect-tester.jorgelbg.me/
  if "_dissectfailure" in [tags] {
      drop { }
  }

  mutate {
    add_field => {
     "host" => "%{[agent][hostname]}"
    }
  }

  if [service] == "mysql" {
    date {
      match => [ "templogdate", "yyyy-MM-dd HH:mm:ss" ]
      target => "logdate"
    }
  } else {
    date {
      match  => [ "templogdate", ISO8601 ]
      target => "logdate"
    }
  }

  mutate {
    remove_field => ["message", "source" , "templogdate", "prospector", "agent", "jobinfo", "log", "input", "ecs", "key_value_pairs", "kafka_mod"]
  }
  <% if @http_output -%>
  truncate {
    fields => "log_message"
    length_bytes => "<%=node['logstash']['managed_cloud']['max_size']%>"
  }
  <% end -%>
}

output {
  <% if @elastic_output -%>
  opensearch {
    hosts => [<%= @elastic_addr %>]
    index => "<%= node['logstash']['service_index'] %>%{+YYYY.MM.dd}"
    <% if node['elastic']['opensearch_security']['enabled'] %>
    user => "<%=node['elastic']['opensearch_security']['logstash']['username']%>"
    password => "<%=node['elastic']['opensearch_security']['logstash']['password']%>"
    <% if node['elastic']['opensearch_security']['https']['enabled'] %>
    cacert => "<%= @hops_ca %>"
    ssl => true
    <% end %>
    <% end %>
  }
  <% end -%>

  <% if @http_output -%>
  http {
    format => "json_batch"
    headers => ["x-api-key", "API_KEY"]
    http_compression => false
    http_method => "post"
    url => "URL"
    follow_redirects => false
  }
  <% end -%>
}
